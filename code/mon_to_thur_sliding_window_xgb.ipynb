{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=1)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../dataofweek/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取base_feature\n",
    "def get_base_feature(df):\n",
    "    df['time'] = df.START_DATE.apply(lambda x:x[:19])\n",
    "    df['time'] = pd.to_datetime(df['time'],format='%Y-%m-%d-%H.%M.%S')\n",
    "    timedelta = df['time'] - pd.datetime(df['time'].dt.year[0],df['time'].dt.month[0],df['time'].dt.day[0],0,0,0)\n",
    "\n",
    "    df['hour'] = df.START_DATE.apply(lambda x:int(x[11:13]))\n",
    "    \n",
    "    df['ten_min'] = timedelta.dt.seconds/600\n",
    "    df['ten_min'] = df['ten_min'].astype(int)\n",
    "    \n",
    "    df['five_min'] = timedelta.dt.seconds/300\n",
    "    df['five_min'] = df['five_min'].astype(int)\n",
    "    \n",
    "    \n",
    "    df.TRADE_TYPE[df.TRADE_TYPE==21] = 1\n",
    "    df.TRADE_TYPE[df.TRADE_TYPE==22] = 0\n",
    "    \n",
    "    result = df.groupby(['date','TRADE_ADDRESS','TERMINAL_ID','SAM_ID','RECORD_ROW','hour','ten_min','five_min']).TRADE_TYPE.agg(['count','sum']).reset_index()\n",
    "    \n",
    "    result['inNums'] = result['sum']\n",
    "    result['outNums'] = result['count'] - result['sum']\n",
    "    del result['count'],result['sum']\n",
    "    \n",
    "    result.date = pd.to_datetime(result.date)\n",
    "    result['week'] = result.date.dt.dayofweek+1\n",
    "    del df\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据EDA的分析进行数据的读取\n",
    "data_list = ['12','13','14','15','16']\n",
    "data1 = pd.DataFrame()\n",
    "for i in data_list:\n",
    "    file = str(i)+'_week.csv'\n",
    "    df = pd.read_csv(path+file)\n",
    "    data1 = pd.concat([data1,df],axis=0,ignore_index=True)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data1['TERMINAL_ID'] = le.fit_transform(data1['TERMINAL_ID'].values)\n",
    "data1['SAM_ID'] = le.fit_transform(data1['SAM_ID'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "szy = data1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_base_feature(szy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.week!=5)&(data.week!=6)&(data.week!=7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9042608, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_before_trans(x,dic_):\n",
    "    if x in dic_.keys():\n",
    "        return dic_[x]\n",
    "    else:\n",
    "        return np.nan\n",
    "def generate_fea_y(df, day, n):\n",
    "    df_feature_y   =  df.loc[df.day_idex == day].copy() \n",
    "    \n",
    "    df_feature_y['tmp_10_minutes'] = df_feature_y['TRADE_ADDRESS'].values * 1000 + df_feature_y['ten_min'].values\n",
    "    df_feature_y['tmp_hours']      = df_feature_y['TRADE_ADDRESS'].values * 1000 + df_feature_y['hour'].values\n",
    "    \n",
    "    for i in range(n): # 前n天每一天\n",
    "        d = day - i - 1\n",
    "        df_d = df.loc[df.day_idex == d].copy() # 当天的数据\n",
    "        \n",
    "        # 特征1：过去在该时间段（一样的时间段,10minutes）有多少出入量\n",
    "        df_d['tmp_10_minutes'] = df['TRADE_ADDRESS'] * 1000 + df['ten_min']  \n",
    "        df_d['tmp_hours']      = df['TRADE_ADDRESS'] * 1000 + df['hour']\n",
    "        \n",
    "        # sum\n",
    "        dic_innums  = df_d.groupby(['tmp_10_minutes'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_10_minutes'])['outNums'].sum().to_dict()\n",
    "        \n",
    "        df_feature_y['_bf_' + str(day -d) + '_innum_10minutes']  =  df_feature_y['tmp_10_minutes'].map(dic_innums).values\n",
    "        df_feature_y['_bf_' + str(day -d) + '_outnum_10minutes'] =  df_feature_y['tmp_10_minutes'].map(dic_outnums).values\n",
    "        \n",
    "        # 特征2：过去在该时间段（小时）有多少出入量\n",
    "        dic_innums  = df_d.groupby(['tmp_hours'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours'])['outNums'].sum().to_dict()   \n",
    "        df_feature_y['_bf_' + str(day -d) + '_innum_hour']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf_' + str(day -d) + '_outnum_hour'] =  df_feature_y['tmp_hours'].map(dic_outnums).values   \n",
    "        \n",
    "        # mean,max,min\n",
    "        dic_innums  = df_d.groupby(['tmp_hours'])['inNums'].mean().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours'])['outNums'].mean().to_dict() \n",
    "        df_feature_y['_bf_' + str(day -d) + '_innum_hour_mean']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf_' + str(day -d) + '_outnum_hour_mean'] =  df_feature_y['tmp_hours'].map(dic_outnums).values\n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_hours'])['inNums'].max().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours'])['outNums'].max().to_dict() \n",
    "        df_feature_y['_bf_' + str(day -d) + '_innum_hour_max']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf_' + str(day -d) + '_outnum_hour_max'] =  df_feature_y['tmp_hours'].map(dic_outnums).values\n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_hours'])['inNums'].min().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours'])['outNums'].min().to_dict() \n",
    "        df_feature_y['_bf_' + str(day -d) + '_innum_hour_min']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf_' + str(day -d) + '_outnum_hour_min'] =  df_feature_y['tmp_hours'].map(dic_outnums).values\n",
    "        \n",
    "        # 特征3: 上10分钟\n",
    "        df_d['tmp_10_minutes_bf'] = df['TRADE_ADDRESS'] * 1000 + df['ten_min'] - 1\n",
    "        df_d['tmp_hours_bf']      = df['TRADE_ADDRESS'] * 1000 + df['hour'] - 1\n",
    "        # sum\n",
    "        dic_innums  = df_d.groupby(['tmp_10_minutes_bf'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_10_minutes_bf'])['outNums'].sum().to_dict()\n",
    "        df_feature_y['_bf1_' + str(day -d) + '_innum_10minutes']  =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_innums)).values\n",
    "        df_feature_y['_bf1_' + str(day -d) + '_outnum_10minutes'] =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_outnums)).values\n",
    "        \n",
    "        # 特征4： 上个小时情况\n",
    "        dic_innums  = df_d.groupby(['tmp_hours_bf'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours_bf'])['outNums'].sum().to_dict()   \n",
    "        df_feature_y['_bf1_' + str(day -d) + '_innum_hour']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf1_' + str(day -d) + '_outnum_hour'] =  df_feature_y['tmp_hours'].map(dic_outnums).values\n",
    "        # mean,max,min\n",
    "        dic_innums  = df_d.groupby(['tmp_hours_bf'])['inNums'].mean().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours_bf'])['outNums'].mean().to_dict()   \n",
    "        df_feature_y['_bf1_' + str(day -d) + '_innum_hour_mean']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf1_' + str(day -d) + '_outnum_hour_mean'] =  df_feature_y['tmp_hours'].map(dic_outnums).values\n",
    "        dic_innums  = df_d.groupby(['tmp_hours_bf'])['inNums'].max().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours_bf'])['outNums'].max().to_dict()   \n",
    "        df_feature_y['_bf1_' + str(day -d) + '_innum_hour_max']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf1_' + str(day -d) + '_outnum_hour_max'] =  df_feature_y['tmp_hours'].map(dic_outnums).values\n",
    "        dic_innums  = df_d.groupby(['tmp_hours_bf'])['inNums'].min().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours_bf'])['outNums'].min().to_dict()   \n",
    "        df_feature_y['_bf1_' + str(day -d) + '_innum_hour_min']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf1_' + str(day -d) + '_outnum_hour_min'] =  df_feature_y['tmp_hours'].map(dic_outnums).values\n",
    "        \n",
    "        ###############################上20分钟/上2个小时的情况(有提升)##################################################### \n",
    "        df_d['tmp_10_minutes_bf2'] = df_d['TRADE_ADDRESS'] * 1000 + df_d['ten_min'] - 2\n",
    "        df_d['tmp_hours_bf2']      = df_d['TRADE_ADDRESS'] * 1000 + df_d['hour'] - 2\n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_10_minutes_bf2'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours_bf2'])['outNums'].sum().to_dict()\n",
    "\n",
    "        df_feature_y['_bf2_' + str(day -d) + '_innum_10minutes']  =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_innums)).values\n",
    "        df_feature_y['_bf2_' + str(day -d) + '_outnum_10minutes'] =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_outnums)).values\n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_hours_bf2'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours_bf2'])['outNums'].sum().to_dict()\n",
    "         \n",
    "        df_feature_y['_bf2_' + str(day -d) + '_innum_hour']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf2_' + str(day -d) + '_outnum_hour'] =  df_feature_y['tmp_hours'].map(dic_outnums).values \n",
    "    \n",
    "         ###############################后10分钟/下一个小时的情况(有提升)#####################################################\n",
    "        \n",
    "        df_d['tmp_10_minutes_la'] = df_d['TRADE_ADDRESS'] * 1000 + df_d['ten_min'] + 1\n",
    "        df_d['tmp_hours_la']      = df_d['TRADE_ADDRESS'] * 1000 + df_d['hour'] + 1\n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_10_minutes_la'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_10_minutes_la'])['outNums'].sum().to_dict()\n",
    "\n",
    "        df_feature_y['_la1_' + str(day -d) + '_innum_10minutes']  =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_innums)).values\n",
    "        df_feature_y['_la1_' + str(day -d) + '_outnum_10minutes'] =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_outnums)).values\n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_hours_la'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours_la'])['outNums'].sum().to_dict()\n",
    "         \n",
    "        df_feature_y['_la1_' + str(day -d) + '_innum_hour']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_la1_' + str(day -d) + '_outnum_hour'] =  df_feature_y['tmp_hours'].map(dic_outnums).values \n",
    "        ###############################后10分钟的情况(有提升)#####################################################\n",
    "        \n",
    "        df_d['tmp_10_minutes_la2'] = df_d['TRADE_ADDRESS'] * 1000 + df_d['ten_min'] + 2 \n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_10_minutes_la2'])['inNums'].sum().to_dict() \n",
    "        dic_outnums = df_d.groupby(['tmp_10_minutes_la2'])['outNums'].sum().to_dict()\n",
    "\n",
    "        df_feature_y['_la2_' + str(day -d) + '_innum_10minutes']  =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_innums)).values\n",
    "        df_feature_y['_la2_' + str(day -d) + '_outnum_10minutes'] =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_outnums)).values\n",
    "         \n",
    "    \n",
    "    \n",
    "        ###############################后30分钟/下一个小时的情况(有提升)#####################################################\n",
    "        \n",
    "        df_d['tmp_10_minutes_la3'] = df_d['TRADE_ADDRESS'] * 1000 + df_d['ten_min'] + 3  \n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_10_minutes_la3'])['inNums'].sum().to_dict() \n",
    "        dic_outnums = df_d.groupby(['tmp_10_minutes_la3'])['outNums'].sum().to_dict()\n",
    "\n",
    "        df_feature_y['_la3_' + str(day -d) + '_innum_10minutes']  =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_innums)).values\n",
    "        df_feature_y['_la3_' + str(day -d) + '_outnum_10minutes'] =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_outnums)).values\n",
    "        \n",
    "    \n",
    "        df_d['tmp_10_minutes_bf3'] = df_d['TRADE_ADDRESS'] * 1000 + df_d['ten_min'] - 3\n",
    "        df_d['tmp_hours_bf3']      = df_d['TRADE_ADDRESS'] * 1000 + df_d['hour'] - 3\n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_10_minutes_bf3'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours_bf3'])['outNums'].sum().to_dict()\n",
    "\n",
    "        df_feature_y['_bf3_' + str(day -d) + '_innum_10minutes']  =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_innums)).values\n",
    "        df_feature_y['_bf3_' + str(day -d) + '_outnum_10minutes'] =  df_feature_y['tmp_10_minutes'].agg(lambda x: time_before_trans(x,dic_outnums)).values\n",
    "        \n",
    "        dic_innums  = df_d.groupby(['tmp_hours_bf3'])['inNums'].sum().to_dict()\n",
    "        dic_outnums = df_d.groupby(['tmp_hours_bf3'])['outNums'].sum().to_dict()\n",
    "         \n",
    "        df_feature_y['_bf3_' + str(day -d) + '_innum_hour']  =  df_feature_y['tmp_hours'].map(dic_innums).values\n",
    "        df_feature_y['_bf3_' + str(day -d) + '_outnum_hour'] =  df_feature_y['tmp_hours'].map(dic_outnums).values \n",
    "        \n",
    "    \n",
    "    for col in ['tmp_10_minutes','tmp_hours']:\n",
    "        del df_feature_y[col]\n",
    "        \n",
    "    return df_feature_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list = list(data.date.unique())\n",
    "day_idex = list(range(21))\n",
    "day_idex.remove(0)\n",
    "day_idex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day_idex'] = 0\n",
    "for i in range(20):\n",
    "    data.loc[data.date==date_list[i], 'day_idex']= data.loc[data.date==date_list[i], 'day_idex'].apply(lambda x:day_idex[i]) \n",
    "    \n",
    "data.week = data.date.dt.dayofweek+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_y = pd.DataFrame()\n",
    "for day in range(5,21):\n",
    "    df_feature_tmp = generate_fea_y(data, day = day, n=4)\n",
    "    df_feature_y   = pd.concat([df_feature_y,df_feature_tmp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7263330, 156)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['_innum_10minutes','_outnum_10minutes','_innum_hour','_outnum_hour']\n",
    "# # 过去n天的sum,mean\n",
    "for i in range(2,4):\n",
    "    for f in columns:\n",
    "        colname1 = '_bf_'+str(i)+'_'+'days'+f+'_sum'\n",
    "        df_feature_y[colname1] = 0\n",
    "        \n",
    "        for d in range(1,i+1):\n",
    "            df_feature_y[colname1] = df_feature_y[colname1] + df_feature_y['_bf_'+str(d) +f]\n",
    "            \n",
    "        colname2 = '_bf_'+str(d)+'_'+'days'+f+'_mean'\n",
    "        df_feature_y[colname2] = df_feature_y[colname1] / i\n",
    "        \n",
    "        \n",
    "# 过去n天的mean的差分\n",
    "for i in range(2,4): \n",
    "    for f in columns:\n",
    "        colname1 = '_bf_'+str(d)+'_'+'days'+f+'_mean'\n",
    "        colname2 = '_bf_'+str(d)+'_'+'days'+f+'_mean_diff'\n",
    "        df_feature_y[colname2] = df_feature_y[colname1].diff(1)\n",
    "        df_feature_y.loc[(df_feature_y.hour==0)&(df_feature_y.ten_min==0), colname2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['_innum_10minutes','_outnum_10minutes','_innum_hour','_outnum_hour']\n",
    "# # 过去n天的sum,mean\n",
    "for i in range(2,5):\n",
    "    for f in columns:\n",
    "        colname1 = '_bf_'+str(i)+'_'+'days'+f+'_sum'\n",
    "        df_feature_y[colname1] = 0\n",
    "        \n",
    "        for d in range(1,i+1):\n",
    "            df_feature_y[colname1] = df_feature_y[colname1] + df_feature_y['_bf_'+str(d) +f]\n",
    "            \n",
    "        colname2 = '_bf_'+str(d)+'_'+'days'+f+'_mean'\n",
    "        df_feature_y[colname2] = df_feature_y[colname1] / i\n",
    "        \n",
    "        \n",
    "# 过去n天的mean的差分\n",
    "for i in range(2,5): \n",
    "    for f in columns:\n",
    "        colname1 = '_bf_'+str(d)+'_'+'days'+f+'_mean'\n",
    "        colname2 = '_bf_'+str(d)+'_'+'days'+f+'_mean_diff'\n",
    "        df_feature_y[colname2] = df_feature_y[colname1].diff(1)\n",
    "        df_feature_y.loc[(df_feature_y.hour==0)&(df_feature_y.ten_min==0), colname2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stationID_fea(df):\n",
    "    df_station               = pd.DataFrame()\n",
    "    df_station['TRADE_ADDRESS']  = df['TRADE_ADDRESS'].unique()\n",
    "    df_station               = df_station.sort_values('TRADE_ADDRESS')\n",
    "    \n",
    "    tmp1  = df.groupby(['TRADE_ADDRESS'])['TERMINAL_ID'].nunique().to_frame('TRADE_ADDRESS_TERMINAL_ID_nunique').reset_index()\n",
    "    tmp2  = df.groupby(['TRADE_ADDRESS'])['CARD_ID'].nunique().to_frame('TRADE_ADDRESS_CARD_ID_nunique').reset_index()\n",
    "    tmp3  = df.groupby(['TRADE_ADDRESS'])['FILE_ID'].nunique().to_frame('TRADE_ADDRESS_FILE_ID_nunique').reset_index()\n",
    "    tmp4  = df.groupby(['TRADE_ADDRESS'])['CARD_SN'].nunique().to_frame('TRADE_ADDRESS_CARD_SN_nunique').reset_index()\n",
    "    tmp5  = df.groupby(['TRADE_ADDRESS'])['TERMINAL_SN'].nunique().to_frame('TRADE_ADDRESS_TERMINAL_SN_nunique').reset_index()\n",
    "    tmp6  = df.groupby(['TRADE_ADDRESS'])['TAC'].nunique().to_frame('TRADE_ADDRESS_TAC_nunique').reset_index()\n",
    "    tmp7  = df.groupby(['TRADE_ADDRESS'])['SAM_ID'].nunique().to_frame('TRADE_ADDRESS_SAM_ID_nunique').reset_index()\n",
    "    tmp8  = df.groupby(['TRADE_ADDRESS'])['SAM_SN'].nunique().to_frame('TRADE_ADDRESS_SAM_SN_nunique').reset_index()\n",
    "    tmp9  = df.groupby(['TRADE_ADDRESS'])['CARD_IDM'].nunique().to_frame('TRADE_ADDRESS_CARD_IDM_nunique').reset_index()\n",
    "\n",
    "    df_station = df_station.merge(tmp1,on ='TRADE_ADDRESS', how='left')\n",
    "    df_station = df_station.merge(tmp2,on ='TRADE_ADDRESS', how='left')\n",
    "    df_station = df_station.merge(tmp3,on ='TRADE_ADDRESS', how='left')\n",
    "    df_station = df_station.merge(tmp4,on ='TRADE_ADDRESS', how='left')\n",
    "    df_station = df_station.merge(tmp5,on ='TRADE_ADDRESS', how='left')\n",
    "    df_station = df_station.merge(tmp6,on ='TRADE_ADDRESS', how='left')\n",
    "    df_station = df_station.merge(tmp7,on ='TRADE_ADDRESS', how='left')\n",
    "    df_station = df_station.merge(tmp8,on ='TRADE_ADDRESS', how='left')\n",
    "    df_station = df_station.merge(tmp9,on ='TRADE_ADDRESS', how='left')\n",
    "\n",
    "    \n",
    "    for pivot_cols in tqdm_notebook(['CARD_TYPE','CARD_TYPE_EX','CITY_CODE','INDUSTRY_CODE','hour','week']):\n",
    "        tmp = df.groupby(['TRADE_ADDRESS',pivot_cols])['TERMINAL_ID'].count().to_frame('TRADE_ADDRESS'+pivot_cols+'_cnt').reset_index()\n",
    "        df_tmp = tmp.pivot(index = 'TRADE_ADDRESS', columns=pivot_cols, values='TRADE_ADDRESS'+pivot_cols+'_cnt')\n",
    "        cols   = ['TRADE_ADDRESS'+pivot_cols+'_cnt' + str(col) for col in df_tmp.columns]\n",
    "        df_tmp.columns = cols\n",
    "        df_tmp.reset_index(inplace = True)\n",
    "        df_station = df_station.merge(df_tmp, on ='TRADE_ADDRESS', how='left')\n",
    "    return df_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(szy.CARD_TYPE_EX.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = ['14']\n",
    "df_station = pd.DataFrame()\n",
    "for i in data_list:\n",
    "    file = str(i)+'_week.csv'\n",
    "    df = pd.read_csv(path+file)\n",
    "    df_station = pd.concat([df_station,df],axis=0,ignore_index=True)\n",
    "    \n",
    "df_station['time'] = df_station.START_DATE.apply(lambda x:x[:19])\n",
    "df_station['time'] = pd.to_datetime(df_station['time'],format='%Y-%m-%d-%H.%M.%S')\n",
    "timedelta = df_station['time'] - pd.datetime(df_station['time'].dt.year[0],df_station['time'].dt.month[0],df_station['time'].dt.day[0],0,0,0)\n",
    "df_station['hour'] = df_station.START_DATE.apply(lambda x:int(x[11:13]))\n",
    "df_station['ten_min'] = timedelta.dt.seconds/600\n",
    "df_station['ten_min'] = df_station['ten_min'].astype(int)\n",
    "df_station.date = pd.to_datetime(df_station.date)\n",
    "df_station['week'] = df_station.date.dt.dayofweek+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236830fa9247496197e5697d18582ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_station = get_stationID_fea(df_station)\n",
    "df_station.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_feature_y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(df_station,on=['TRADE_ADDRESS'],how='left')\n",
    "data.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = ['TRADE_ADDRESS',\n",
    " 'TERMINAL_ID',\n",
    " 'SAM_ID',\n",
    " 'RECORD_ROW',\n",
    " 'hour',\n",
    " 'ten_min',\n",
    " 'five_min',\n",
    " 'inNums',\n",
    " 'outNums',\n",
    " 'week',\n",
    " '_bf_1_innum_10minutes',\n",
    " '_bf_1_outnum_10minutes',\n",
    " '_bf_1_innum_hour',\n",
    " '_bf_1_outnum_hour',\n",
    " '_bf_1_innum_hour_mean',\n",
    " '_bf_1_outnum_hour_mean',\n",
    " '_bf_1_outnum_hour_max',\n",
    " '_bf1_1_innum_10minutes',\n",
    " '_bf1_1_outnum_10minutes',\n",
    " '_bf1_1_innum_hour',\n",
    " '_bf1_1_outnum_hour',\n",
    " '_bf1_1_innum_hour_mean',\n",
    " '_bf1_1_outnum_hour_mean',\n",
    " '_bf1_1_outnum_hour_max',\n",
    " '_bf2_1_innum_10minutes',\n",
    " '_bf2_1_innum_hour',\n",
    " '_bf2_1_outnum_hour',\n",
    " '_la1_1_innum_10minutes',\n",
    " '_la1_1_outnum_10minutes',\n",
    " '_la1_1_innum_hour',\n",
    " '_la1_1_outnum_hour',\n",
    " '_la2_1_innum_10minutes',\n",
    " '_la2_1_outnum_10minutes',\n",
    " '_la3_1_innum_10minutes',\n",
    " '_la3_1_outnum_10minutes',\n",
    " '_bf3_1_innum_10minutes',\n",
    " '_bf3_1_innum_hour',\n",
    " '_bf3_1_outnum_hour',\n",
    " '_bf_2_innum_10minutes',\n",
    " '_bf_2_outnum_10minutes',\n",
    " '_bf_2_innum_hour',\n",
    " '_bf_2_outnum_hour',\n",
    " '_bf_2_innum_hour_mean',\n",
    " '_bf_2_outnum_hour_mean',\n",
    " '_bf_2_outnum_hour_max',\n",
    " '_bf1_2_innum_10minutes',\n",
    " '_bf1_2_outnum_10minutes',\n",
    " '_bf1_2_innum_hour',\n",
    " '_bf1_2_outnum_hour',\n",
    " '_bf1_2_innum_hour_mean',\n",
    " '_bf1_2_outnum_hour_mean',\n",
    " '_bf1_2_outnum_hour_max',\n",
    " '_bf2_2_innum_10minutes',\n",
    " '_bf2_2_innum_hour',\n",
    " '_bf2_2_outnum_hour',\n",
    " '_la1_2_innum_10minutes',\n",
    " '_la1_2_outnum_10minutes',\n",
    " '_la1_2_innum_hour',\n",
    " '_la1_2_outnum_hour',\n",
    " '_la2_2_innum_10minutes',\n",
    " '_la2_2_outnum_10minutes',\n",
    " '_la3_2_innum_10minutes',\n",
    " '_la3_2_outnum_10minutes',\n",
    " '_bf3_2_innum_10minutes',\n",
    " '_bf3_2_innum_hour',\n",
    " '_bf3_2_outnum_hour',\n",
    " '_bf_3_innum_10minutes',\n",
    " '_bf_3_outnum_10minutes',\n",
    " '_bf_3_innum_hour',\n",
    " '_bf_3_outnum_hour',\n",
    " '_bf_3_innum_hour_mean',\n",
    " '_bf_3_outnum_hour_mean',\n",
    " '_bf_3_outnum_hour_max',\n",
    " '_bf1_3_innum_10minutes',\n",
    " '_bf1_3_outnum_10minutes',\n",
    " '_bf1_3_innum_hour',\n",
    " '_bf1_3_outnum_hour',\n",
    " '_bf1_3_innum_hour_mean',\n",
    " '_bf1_3_outnum_hour_mean',\n",
    " '_bf1_3_outnum_hour_max',\n",
    " '_bf2_3_innum_10minutes',\n",
    " '_bf2_3_innum_hour',\n",
    " '_bf2_3_outnum_hour',\n",
    " '_la1_3_innum_10minutes',\n",
    " '_la1_3_outnum_10minutes',\n",
    " '_la1_3_innum_hour',\n",
    " '_la1_3_outnum_hour',\n",
    " '_la2_3_innum_10minutes',\n",
    " '_la2_3_outnum_10minutes',\n",
    " '_la3_3_innum_10minutes',\n",
    " '_la3_3_outnum_10minutes',\n",
    " '_bf3_3_innum_10minutes',\n",
    " '_bf3_3_innum_hour',\n",
    " '_bf3_3_outnum_hour',\n",
    " '_bf_4_innum_10minutes',\n",
    " '_bf_4_outnum_10minutes',\n",
    " '_bf_4_innum_hour',\n",
    " '_bf_4_outnum_hour',\n",
    " '_bf_4_innum_hour_mean',\n",
    " '_bf_4_outnum_hour_mean',\n",
    " '_bf_4_outnum_hour_max',\n",
    " '_bf1_4_innum_10minutes',\n",
    " '_bf1_4_outnum_10minutes',\n",
    " '_bf1_4_innum_hour',\n",
    " '_bf1_4_outnum_hour',\n",
    " '_bf1_4_innum_hour_mean',\n",
    " '_bf1_4_outnum_hour_mean',\n",
    " '_bf1_4_outnum_hour_max',\n",
    " '_bf2_4_innum_10minutes',\n",
    " '_bf2_4_innum_hour',\n",
    " '_bf2_4_outnum_hour',\n",
    " '_la1_4_innum_10minutes',\n",
    " '_la1_4_outnum_10minutes',\n",
    " '_la1_4_innum_hour',\n",
    " '_la1_4_outnum_hour',\n",
    " '_la2_4_innum_10minutes',\n",
    " '_la2_4_outnum_10minutes',\n",
    " '_la3_4_innum_10minutes',\n",
    " '_la3_4_outnum_10minutes',\n",
    " '_bf3_4_innum_10minutes',\n",
    " '_bf3_4_innum_hour',\n",
    " '_bf3_4_outnum_hour',\n",
    " '_bf_2_days_innum_10minutes_sum',\n",
    " '_bf_2_days_innum_10minutes_mean',\n",
    " '_bf_2_days_outnum_10minutes_sum',\n",
    " '_bf_2_days_outnum_10minutes_mean',\n",
    " '_bf_2_days_innum_hour_sum',\n",
    " '_bf_2_days_innum_hour_mean',\n",
    " '_bf_2_days_outnum_hour_sum',\n",
    " '_bf_2_days_outnum_hour_mean',\n",
    " '_bf_3_days_innum_10minutes_sum',\n",
    " '_bf_3_days_innum_10minutes_mean',\n",
    " '_bf_3_days_outnum_10minutes_sum',\n",
    " '_bf_3_days_outnum_10minutes_mean',\n",
    " '_bf_3_days_innum_hour_sum',\n",
    " '_bf_3_days_innum_hour_mean',\n",
    " '_bf_3_days_outnum_hour_sum',\n",
    " '_bf_3_days_outnum_hour_mean',\n",
    " '_bf_3_days_innum_10minutes_mean_diff',\n",
    " '_bf_3_days_outnum_10minutes_mean_diff',\n",
    " '_bf_3_days_innum_hour_mean_diff',\n",
    " '_bf_3_days_outnum_hour_mean_diff',\n",
    " '_bf_4_days_innum_10minutes_sum',\n",
    " '_bf_4_days_innum_10minutes_mean',\n",
    " '_bf_4_days_outnum_10minutes_sum',\n",
    " '_bf_4_days_outnum_10minutes_mean',\n",
    " '_bf_4_days_innum_hour_sum',\n",
    " '_bf_4_days_innum_hour_mean',\n",
    " '_bf_4_days_outnum_hour_sum',\n",
    " '_bf_4_days_outnum_hour_mean',\n",
    " '_bf_4_days_innum_10minutes_mean_diff',\n",
    " '_bf_4_days_outnum_10minutes_mean_diff',\n",
    " '_bf_4_days_innum_hour_mean_diff',\n",
    " '_bf_4_days_outnum_hour_mean_diff',\n",
    " 'TRADE_ADDRESS_TERMINAL_ID_nunique',\n",
    " 'TRADE_ADDRESS_CARD_ID_nunique',\n",
    " 'TRADE_ADDRESS_FILE_ID_nunique',\n",
    " 'TRADE_ADDRESS_CARD_SN_nunique',\n",
    " 'TRADE_ADDRESS_TERMINAL_SN_nunique',\n",
    " 'TRADE_ADDRESS_TAC_nunique',\n",
    " 'TRADE_ADDRESS_SAM_ID_nunique',\n",
    " 'TRADE_ADDRESS_SAM_SN_nunique',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt50',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt66',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt81',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt87',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt88',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt95',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt98',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt1',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt2',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt3',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt4',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt5',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt6',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt7',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt90',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt1100',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt2260',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt3000',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt3300',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt4500',\n",
    " 'TRADE_ADDRESSINDUSTRY_CODE_cnt1',\n",
    " 'TRADE_ADDRESSINDUSTRY_CODE_cnt3',\n",
    " 'TRADE_ADDRESShour_cnt5',\n",
    " 'TRADE_ADDRESShour_cnt6',\n",
    " 'TRADE_ADDRESShour_cnt7',\n",
    " 'TRADE_ADDRESShour_cnt8',\n",
    " 'TRADE_ADDRESShour_cnt10',\n",
    " 'TRADE_ADDRESShour_cnt13',\n",
    " 'TRADE_ADDRESShour_cnt17',\n",
    " 'TRADE_ADDRESShour_cnt18',\n",
    " 'TRADE_ADDRESShour_cnt19',\n",
    " 'TRADE_ADDRESShour_cnt20',\n",
    " 'TRADE_ADDRESShour_cnt21',\n",
    " 'TRADE_ADDRESShour_cnt22',\n",
    " 'TRADE_ADDRESShour_cnt23',\n",
    " 'TRADE_ADDRESSweek_cnt1',\n",
    " 'TRADE_ADDRESSweek_cnt2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb参数\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'num_leaves': 63,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_seed':0,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 1,\n",
    "    'reg_alpha':1,\n",
    "    'reg_lambda':2,\n",
    "    'min_child_weight':6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########inNums\n",
    "# train_in = data[data.id_week!=4]\n",
    "train_in = data[data.day_idex<13]\n",
    "train_in = train_in[all_columns]\n",
    "y_train_in = train_in['inNums']\n",
    "\n",
    "del train_in['outNums'],train_in['inNums']\n",
    "\n",
    "valid = data[(data.day_idex>=13)&(data.day_idex<=16)]\n",
    "valid = valid[all_columns]\n",
    "y_valid = valid['inNums']\n",
    "del valid['outNums'],valid['inNums']\n",
    "# y_valid = np.log1p(y_valid)\n",
    "\n",
    "test_in = data[data.day_idex>=17]\n",
    "test_in = test_in[all_columns]\n",
    "y_test_in = test_in['inNums']\n",
    "del test_in['inNums'],test_in['outNums']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3608713, 197)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1818654, 197)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[data.day_idex>=17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:0.498558\tval-mae:0.498512\n",
      "Multiple eval metrics have been passed: 'val-mae' will be used for early stopping.\n",
      "\n",
      "Will train until val-mae hasn't improved in 100 rounds.\n",
      "[100]\ttrain-mae:0.385465\tval-mae:0.383204\n",
      "[200]\ttrain-mae:0.299676\tval-mae:0.296148\n",
      "[300]\ttrain-mae:0.235681\tval-mae:0.231864\n",
      "[400]\ttrain-mae:0.186029\tval-mae:0.182236\n",
      "[500]\ttrain-mae:0.149766\tval-mae:0.146973\n",
      "[600]\ttrain-mae:0.122376\tval-mae:0.120562\n",
      "[700]\ttrain-mae:0.09934\tval-mae:0.098541\n",
      "[800]\ttrain-mae:0.083976\tval-mae:0.083879\n",
      "[900]\ttrain-mae:0.070754\tval-mae:0.071316\n",
      "[1000]\ttrain-mae:0.05857\tval-mae:0.059718\n",
      "[1100]\ttrain-mae:0.048829\tval-mae:0.050606\n",
      "[1200]\ttrain-mae:0.040908\tval-mae:0.04337\n",
      "[1300]\ttrain-mae:0.035208\tval-mae:0.038264\n",
      "[1400]\ttrain-mae:0.030568\tval-mae:0.034188\n",
      "[1500]\ttrain-mae:0.027012\tval-mae:0.031107\n",
      "[1600]\ttrain-mae:0.024153\tval-mae:0.028576\n",
      "[1700]\ttrain-mae:0.021972\tval-mae:0.026668\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_in, label = y_train_in)\n",
    "dtest = xgb.DMatrix(test_in)\n",
    "dval = xgb.DMatrix(valid, label = y_valid)\n",
    "watchlist = [(dtrain, 'train'),(dval, 'val')]\n",
    "xgb_params = {'eta': 0.004, 'max_depth': 14, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'mae', 'silent': True, 'nthread': 4}\n",
    "clf1 = xgb.train(dtrain=dtrain, num_boost_round=15000, evals=watchlist, early_stopping_rounds=100, verbose_eval=100, params=xgb_params)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_in = clf1.predict(dtest, ntree_limit=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_in = mean_absolute_error(prediction_in,y_test_in)\n",
    "error_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pre_inNums'] = prediction_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns =['TRADE_ADDRESS',\n",
    " 'TERMINAL_ID',\n",
    " 'SAM_ID',\n",
    " 'RECORD_ROW',\n",
    " 'hour',\n",
    " 'ten_min',\n",
    " 'five_min',\n",
    " 'inNums',\n",
    " 'outNums',\n",
    " 'week',\n",
    " '_bf_1_innum_10minutes',\n",
    " '_bf_1_outnum_10minutes',\n",
    " '_bf_1_innum_hour',\n",
    " '_bf_1_outnum_hour',\n",
    " '_bf_1_innum_hour_mean',\n",
    " '_bf_1_outnum_hour_mean',\n",
    " '_bf_1_outnum_hour_max',\n",
    " '_bf1_1_innum_10minutes',\n",
    " '_bf1_1_outnum_10minutes',\n",
    " '_bf1_1_innum_hour',\n",
    " '_bf1_1_outnum_hour',\n",
    " '_bf1_1_innum_hour_mean',\n",
    " '_bf1_1_outnum_hour_mean',\n",
    " '_bf1_1_outnum_hour_max',\n",
    " '_bf2_1_innum_10minutes',\n",
    " '_bf2_1_innum_hour',\n",
    " '_bf2_1_outnum_hour',\n",
    " '_la1_1_innum_10minutes',\n",
    " '_la1_1_outnum_10minutes',\n",
    " '_la1_1_innum_hour',\n",
    " '_la1_1_outnum_hour',\n",
    " '_la2_1_innum_10minutes',\n",
    " '_la2_1_outnum_10minutes',\n",
    " '_la3_1_innum_10minutes',\n",
    " '_la3_1_outnum_10minutes',\n",
    " '_bf3_1_innum_10minutes',\n",
    " '_bf3_1_innum_hour',\n",
    " '_bf3_1_outnum_hour',\n",
    " '_bf_2_innum_10minutes',\n",
    " '_bf_2_outnum_10minutes',\n",
    " '_bf_2_innum_hour',\n",
    " '_bf_2_outnum_hour',\n",
    " '_bf_2_innum_hour_mean',\n",
    " '_bf_2_outnum_hour_mean',\n",
    " '_bf_2_outnum_hour_max',\n",
    " '_bf1_2_innum_10minutes',\n",
    " '_bf1_2_outnum_10minutes',\n",
    " '_bf1_2_innum_hour',\n",
    " '_bf1_2_outnum_hour',\n",
    " '_bf1_2_innum_hour_mean',\n",
    " '_bf1_2_outnum_hour_mean',\n",
    " '_bf1_2_outnum_hour_max',\n",
    " '_bf2_2_innum_10minutes',\n",
    " '_bf2_2_innum_hour',\n",
    " '_bf2_2_outnum_hour',\n",
    " '_la1_2_innum_10minutes',\n",
    " '_la1_2_outnum_10minutes',\n",
    " '_la1_2_innum_hour',\n",
    " '_la1_2_outnum_hour',\n",
    " '_la2_2_innum_10minutes',\n",
    " '_la2_2_outnum_10minutes',\n",
    " '_la3_2_innum_10minutes',\n",
    " '_la3_2_outnum_10minutes',\n",
    " '_bf3_2_innum_10minutes',\n",
    " '_bf3_2_innum_hour',\n",
    " '_bf3_2_outnum_hour',\n",
    " '_bf_3_innum_10minutes',\n",
    " '_bf_3_outnum_10minutes',\n",
    " '_bf_3_innum_hour',\n",
    " '_bf_3_outnum_hour',\n",
    " '_bf_3_innum_hour_mean',\n",
    " '_bf_3_outnum_hour_mean',\n",
    " '_bf_3_outnum_hour_max',\n",
    " '_bf1_3_innum_10minutes',\n",
    " '_bf1_3_outnum_10minutes',\n",
    " '_bf1_3_innum_hour',\n",
    " '_bf1_3_outnum_hour',\n",
    " '_bf1_3_innum_hour_mean',\n",
    " '_bf1_3_outnum_hour_mean',\n",
    " '_bf1_3_outnum_hour_max',\n",
    " '_bf2_3_innum_10minutes',\n",
    " '_bf2_3_innum_hour',\n",
    " '_bf2_3_outnum_hour',\n",
    " '_la1_3_innum_10minutes',\n",
    " '_la1_3_outnum_10minutes',\n",
    " '_la1_3_innum_hour',\n",
    " '_la1_3_outnum_hour',\n",
    " '_la2_3_innum_10minutes',\n",
    " '_la2_3_outnum_10minutes',\n",
    " '_la3_3_innum_10minutes',\n",
    " '_la3_3_outnum_10minutes',\n",
    " '_bf3_3_innum_10minutes',\n",
    " '_bf3_3_innum_hour',\n",
    " '_bf3_3_outnum_hour',\n",
    " '_bf_4_innum_10minutes',\n",
    " '_bf_4_outnum_10minutes',\n",
    " '_bf_4_innum_hour',\n",
    " '_bf_4_outnum_hour',\n",
    " '_bf_4_innum_hour_mean',\n",
    " '_bf_4_outnum_hour_mean',\n",
    " '_bf_4_outnum_hour_max',\n",
    " '_bf1_4_innum_10minutes',\n",
    " '_bf1_4_outnum_10minutes',\n",
    " '_bf1_4_innum_hour',\n",
    " '_bf1_4_outnum_hour',\n",
    " '_bf1_4_innum_hour_mean',\n",
    " '_bf1_4_outnum_hour_mean',\n",
    " '_bf1_4_outnum_hour_max',\n",
    " '_bf2_4_innum_10minutes',\n",
    " '_bf2_4_innum_hour',\n",
    " '_bf2_4_outnum_hour',\n",
    " '_la1_4_innum_10minutes',\n",
    " '_la1_4_outnum_10minutes',\n",
    " '_la1_4_innum_hour',\n",
    " '_la1_4_outnum_hour',\n",
    " '_la2_4_innum_10minutes',\n",
    " '_la2_4_outnum_10minutes',\n",
    " '_la3_4_innum_10minutes',\n",
    " '_la3_4_outnum_10minutes',\n",
    " '_bf3_4_innum_10minutes',\n",
    " '_bf3_4_innum_hour',\n",
    " '_bf3_4_outnum_hour',\n",
    " '_bf_2_days_innum_10minutes_sum',\n",
    " '_bf_2_days_innum_10minutes_mean',\n",
    " '_bf_2_days_outnum_10minutes_sum',\n",
    " '_bf_2_days_outnum_10minutes_mean',\n",
    " '_bf_2_days_innum_hour_sum',\n",
    " '_bf_2_days_innum_hour_mean',\n",
    " '_bf_2_days_outnum_hour_sum',\n",
    " '_bf_2_days_outnum_hour_mean',\n",
    " '_bf_3_days_innum_10minutes_sum',\n",
    " '_bf_3_days_innum_10minutes_mean',\n",
    " '_bf_3_days_outnum_10minutes_sum',\n",
    " '_bf_3_days_outnum_10minutes_mean',\n",
    " '_bf_3_days_innum_hour_sum',\n",
    " '_bf_3_days_innum_hour_mean',\n",
    " '_bf_3_days_outnum_hour_sum',\n",
    " '_bf_3_days_outnum_hour_mean',\n",
    " '_bf_3_days_innum_10minutes_mean_diff',\n",
    " '_bf_3_days_outnum_10minutes_mean_diff',\n",
    " '_bf_3_days_innum_hour_mean_diff',\n",
    " '_bf_3_days_outnum_hour_mean_diff',\n",
    " '_bf_4_days_innum_10minutes_sum',\n",
    " '_bf_4_days_innum_10minutes_mean',\n",
    " '_bf_4_days_outnum_10minutes_sum',\n",
    " '_bf_4_days_outnum_10minutes_mean',\n",
    " '_bf_4_days_innum_hour_sum',\n",
    " '_bf_4_days_innum_hour_mean',\n",
    " '_bf_4_days_outnum_hour_sum',\n",
    " '_bf_4_days_outnum_hour_mean',\n",
    " '_bf_4_days_innum_10minutes_mean_diff',\n",
    " '_bf_4_days_outnum_10minutes_mean_diff',\n",
    " '_bf_4_days_innum_hour_mean_diff',\n",
    " '_bf_4_days_outnum_hour_mean_diff',\n",
    " 'TRADE_ADDRESS_TERMINAL_ID_nunique',\n",
    " 'TRADE_ADDRESS_CARD_ID_nunique',\n",
    " 'TRADE_ADDRESS_FILE_ID_nunique',\n",
    " 'TRADE_ADDRESS_CARD_SN_nunique',\n",
    " 'TRADE_ADDRESS_TERMINAL_SN_nunique',\n",
    " 'TRADE_ADDRESS_TAC_nunique',\n",
    " 'TRADE_ADDRESS_SAM_ID_nunique',\n",
    " 'TRADE_ADDRESS_SAM_SN_nunique',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt50',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt66',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt81',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt87',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt88',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt95',\n",
    " 'TRADE_ADDRESSCARD_TYPE_cnt98',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt1',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt2',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt3',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt4',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt5',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt6',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt7',\n",
    " 'TRADE_ADDRESSCARD_TYPE_EX_cnt90',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt1100',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt2260',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt3000',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt3300',\n",
    " 'TRADE_ADDRESSCITY_CODE_cnt4500',\n",
    " 'TRADE_ADDRESSINDUSTRY_CODE_cnt1',\n",
    " 'TRADE_ADDRESSINDUSTRY_CODE_cnt3',\n",
    " 'TRADE_ADDRESShour_cnt5',\n",
    " 'TRADE_ADDRESShour_cnt6',\n",
    " 'TRADE_ADDRESShour_cnt7',\n",
    " 'TRADE_ADDRESShour_cnt8',\n",
    " 'TRADE_ADDRESShour_cnt10',\n",
    " 'TRADE_ADDRESShour_cnt13',\n",
    " 'TRADE_ADDRESShour_cnt17',\n",
    " 'TRADE_ADDRESShour_cnt18',\n",
    " 'TRADE_ADDRESShour_cnt19',\n",
    " 'TRADE_ADDRESShour_cnt20',\n",
    " 'TRADE_ADDRESShour_cnt21',\n",
    " 'TRADE_ADDRESShour_cnt22',\n",
    " 'TRADE_ADDRESShour_cnt23',\n",
    " 'TRADE_ADDRESSweek_cnt1',\n",
    " 'TRADE_ADDRESSweek_cnt2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########inNums\n",
    "# train_out = data[data.id_week!=4]\n",
    "train_out = data[data.day_idex<13]\n",
    "train_out = train_out[all_columns]\n",
    "y_train_out = train_out['outNums']\n",
    "del train_out['outNums'],train_out['inNums']\n",
    "\n",
    "valid = data[(data.day_idex>=13)&(data.day_idex<=16)]\n",
    "valid = valid[all_columns]\n",
    "y_valid = valid['outNums']\n",
    "del valid['outNums'],valid['inNums']\n",
    "# y_valid = np.log1p(y_valid)\n",
    "\n",
    "test_out = data[data.day_idex>=17]\n",
    "test_out = test_out[all_columns]\n",
    "y_test_out = test_out['outNums']\n",
    "del test_out['inNums'],test_out['outNums']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_out, label = y_train_out)\n",
    "dtest = xgb.DMatrix(test_out)\n",
    "dval = xgb.DMatrix(valid, label = y_valid)\n",
    "watchlist = [(dtrain, 'train'),(dval, 'val')]\n",
    "xgb_params = {'eta': 0.004, 'max_depth': 14, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'mae', 'silent': True, 'nthread': 4}\n",
    "clf2 = xgb.train(dtrain=dtrain, num_boost_round=30000, evals=watchlist, early_stopping_rounds=100, verbose_eval=1000, params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_out = clf2.predict(dtest, ntree_limit=clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_out = mean_absolute_error(prediction_out,y_test_out)\n",
    "error_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pre_outNums'] = prediction_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = test.groupby(['date','TRADE_ADDRESS']).pre_inNums.agg({'inNums':'sum'}).reset_index()\n",
    "sub2 = test.groupby(['date','TRADE_ADDRESS']).pre_outNums.agg({'outNums':'sum'}).reset_index()\n",
    "sub = sub1.merge(sub2,on = ['date','TRADE_ADDRESS'],how='left')\n",
    "sub['flow'] = sub.inNums + sub.outNums\n",
    "sub['round_pre'] = np.round(sub.flow)\n",
    "sub['round_in'] = np.round(sub.inNums)\n",
    "sub['round_out'] = np.round(sub.outNums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real1 = test.groupby(['date','TRADE_ADDRESS']).inNums.agg({'inNums':'sum'}).reset_index()\n",
    "real2 = test.groupby(['date','TRADE_ADDRESS']).outNums.agg({'outNums':'sum'}).reset_index()\n",
    "real = real1.merge(real2,on = ['date','TRADE_ADDRESS'],how='left')\n",
    "real['flow'] = real.inNums + real.outNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = mean_absolute_error(sub.flow,real.flow)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sub.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_columns = ['date',\n",
    " 'TRADE_ADDRESS',\n",
    " 'round_pre',\n",
    " 'round_in',\n",
    " 'round_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub[sub_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_path = '../result2/'\n",
    "sub.to_csv(re_path+'1_2_3_4_flow_pre_st2_xgb_'+str('%.2f'%error)+'.csv',encoding='utf-8',index=False)\n",
    "real.to_csv(re_path+'1_2_3_4_flow_real_st2.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_list = [15,16,17,18,19,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,20))\n",
    "for i in day_list:\n",
    "    hh = data[data.day_idex==i]\n",
    "    hhh = hh.groupby(['hour']).inNums.agg({'inNums':'sum'}).reset_index()\n",
    "    plt.plot(hhh['hour'],hhh['inNums'],label = i)\n",
    "    \n",
    "legend=plt.legend(title='time', fontsize=30)\n",
    "legend.get_title().set_fontsize(fontsize=30)\n",
    "\n",
    "plt.tick_params(labelsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
